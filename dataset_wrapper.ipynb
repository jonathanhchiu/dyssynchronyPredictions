{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Wrapper\n",
    "I will be explaining the reasoning behind the implementation of the dataset wrapper for the vectorcardiograms and dyssynchrony indices.\n",
    "\n",
    "## Goal\n",
    "The goal is to be able to easily iterate through a given dataset when we are training a neural network. Ideally, we would want to be able to call ```next_batch``` and it would give us the next batch of a specified size within the dataset. \n",
    "\n",
    "## Next Batch\n",
    "We provide additional requirements of the ```next_batch``` function here. They are as follows:\n",
    "* Deliver a specified number of examples upon calling ```next_batch``` for the vectorcardiograms sequences, vectorcardiogram lengths, and the dyssynchrony indices.\n",
    "* The batches are delivered sequentially. For example, if we deliver the the first batch, it should contain example numbers 0 through 9. The second batch should deliver example numbers 10 through 20.\n",
    "* If we have iterated through the entire dataset, then start pulling batches from the beginning. This is reasonable because most often, neural networks are usually trained with more than one epoch (the network sees the entire dataset usually more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Steps\n",
    "### *Step 0: Setup*\n",
    "To download the dataset, please email Chris Villongco for the link to the Dropbox. Once you have access, download the folder ```BiV2``` that corresponds to Patient 2 (our choice of Patient 2 is arbitrary, and we can use any of the patients available). Within that folder, we find the following files and folders:\n",
    "* ```vcg_measured```* The actual (recorded) VCG (not simulated)\n",
    "* ```vcg_model/``` The VCG simulations\n",
    "* ```BiV2_LVdyssync_opt.txt```* The calculated dyssynchrony index (not from simulations)\n",
    "* ```BiV2_LVdyssync.txt``` The dyssynchrony indices resulting from the simulations\n",
    "* ```pts_to_eval.txt```* The parameters of the simulations\n",
    "\n",
    "\\* We are not interested in these files.\n",
    "\n",
    "Once you download and extract it (usually comes as a .zip file), run the following:\n",
    "```\n",
    ">>> cd BiV2/vcg_model\n",
    "```\n",
    "and we are ready to begin!\n",
    "\n",
    "### *Step 1: Rename Files*\n",
    "We wish to rename the files for three reasons:\n",
    "* Impose an ordering on the example numbers that is clearly visible in the file name\n",
    "* Make the filenames more readable\n",
    "* *Maintain* that the filenames are predictable and follow a well-defined format\n",
    "\n",
    "Thus, we will execute the following bash script to rename all the ```.txt``` files in the current directory into something more readable:\n",
    "```\n",
    "a=1\n",
    "for file in allParams-1_ECG_VCG_{1..608}_dump.txt; do \n",
    "    \n",
    "    # Require a 3 digit padding\n",
    "    new=$(printf \"version%03d.txt\" \"$a\")\n",
    "    \n",
    "    # Change the name\n",
    "    mv \"$file\" \"$new\"\n",
    "    let a=a+1\n",
    "done\n",
    "```\n",
    "The result will be 608 files that are renamed to ```version%%%.txt```, where the number is padded with three digits.\n",
    "\n",
    "\n",
    "Since the original filenames were not zero-padded, when we ```ls```, we would get ```allParams-1_ECG_VCG_109_dump.txt``` lexicographically before ```allParams-1_ECG_VCG_10_dump.txt```. Thus, instead of iterating through each ```file in ls *.txt```, we have to iterate through them using curly braces ```{1..608}``` to maintain that ```allParams-1_ECG_VCG_9_dump.txt``` corresponds to ```version009.txt``` and not ```allParams-1_ECG_VCG_109_dump.txt```\n",
    "\n",
    "To show that this has preserved the original ordering, look at the content of the file labelled ```1``` before and after the renaming.\n",
    "\n",
    "#### Before:\n",
    "```\n",
    ">>> head allParams-1_ECG_VCG_1_dump.txt\n",
    "1.14859698e-06\t-8.52689793e-07\t-1.62738886e-07\n",
    "6.27637865e-03\t8.56158099e-04\t-2.80092680e-05\n",
    "1.73977577e-02\t2.37706707e-03\t-8.70847085e-05\n",
    "0.03220872\t0.00439809\t-0.00017971\n",
    "0.04663505\t0.00636597\t-0.00028655\n",
    "0.05990819\t0.00821321\t-0.00043461\n",
    "0.07573148\t0.01035879\t-0.00061512\n",
    "0.09897242\t0.01347624\t-0.0008311\n",
    "0.11859204\t0.01606282\t-0.00100526\n",
    "0.13539736\t0.01838106\t-0.00139427\n",
    "```\n",
    "\n",
    "#### After:\n",
    "```\n",
    ">>> head version001.txt\n",
    "1.14859698e-06\t-8.52689793e-07\t-1.62738886e-07\n",
    "6.27637865e-03\t8.56158099e-04\t-2.80092680e-05\n",
    "1.73977577e-02\t2.37706707e-03\t-8.70847085e-05\n",
    "0.03220872\t0.00439809\t-0.00017971\n",
    "0.04663505\t0.00636597\t-0.00028655\n",
    "0.05990819\t0.00821321\t-0.00043461\n",
    "0.07573148\t0.01035879\t-0.00061512\n",
    "0.09897242\t0.01347624\t-0.0008311\n",
    "0.11859204\t0.01606282\t-0.00100526\n",
    "0.13539736\t0.01838106\t-0.00139427\n",
    "```\n",
    "The first ten lines appear to match. It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Step 2: Convert To NumPy Arrays*\n",
    "We wish to read in each VCG data as a NumPy 2D matrix and store them all in a list (creating a list of 2D matrices, thus becoming 3D). Similarly, we wish to read in each dyssynchrony index, a scalar value, and store them all as a column vector. We will read them in with simple python scripts, provided below (We provided the script as Markdown because it only needs to be executed once, and we have done it for you):\n",
    "\n",
    "#### Read in Vectorcardiogram Simulations with Python\n",
    "```\n",
    "# read_vcg.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize python list containing the vcg lengths and input \n",
    "vcg_length = []\n",
    "vcg = []\n",
    "\n",
    "for index in range(608):\n",
    "\n",
    "\t# Create filename with zero pad\n",
    "\tfilename = 'version{:03d}.txt'.format(index + 1)\n",
    "\n",
    "\t# Read in the text file as numpy matrix\n",
    "\tx = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "\tvcg.append(x)\n",
    "\n",
    "\t# Grab and store the vcg length\n",
    "\tvcg_length.append(x.shape[0])\n",
    "\n",
    "# Convert Python list to NumPy array and save\n",
    "np_vcg_length = np.asarray(vcg_length, dtype=np.int32)\n",
    "np.save(\"vcg_length.npy\", np_vcg_length)\n",
    "\n",
    "np_vcg = np.asarray(vcg, dtype=np.float32)\n",
    "np.save(\"vcg.npy\", np_vcg)\n",
    "\n",
    "```\n",
    "\n",
    "The result should be two files: ```vcg.npy``` and ```vcg_length.npy```, saved in our current directory. We save the length of each VCG simulation because the TensorFlow function ```tf.nn.dynamic_rnn``` accepts the optional parameter ```sequence_length```, an int32/int64 vector sized [batch_size] as a way of checking that the dimensions of our data reflect our design.\n",
    "\n",
    "#### Read in Dyssynchrony Indices With Python\n",
    "We do a similar thing with the corresponding dyssynchrony indices, but they are easier since they all lie in a single file. We run the following script (We provided the script as Markdown because it only needs to be executed once, and we have done it for you):\n",
    "```\n",
    "# read_dyssync.py\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "dyssync = np.loadtxt(\"dyssync.txt\")\n",
    "np.save(\"dyssync.npy\", dyssync)\n",
    "```\n",
    "\n",
    "#### Converting the Dyssynchrony Indices to Class Indices\n",
    "When we save the first file, ```dyssync.npy```, each entry is a real number value between ```0.5``` and ```1```. However, we need to map it to the set of class indices (what each VCG belongs to), namely, the integers between ```0``` and ```4```. The mapping is as follows:\n",
    "* Multiply by 10.\n",
    "* Floor the result.\n",
    "* Subtract 5.\n",
    "* Corner case: if the dyssynchrony index is less than 0.5 (0 is common), then we set those entries to ```0``` (instead of ```0*10 - 5 = -5```).\n",
    "* Corner case: if the dyssynchrony index is exactly 1, then we set those entries to ```4``` (instead of ```1*10 - 5 = 5```).\n",
    "* Convert to int datatype.\n",
    "\n",
    "We execute the following python script to implement the mapping and save it as a new ```.npy``` file:\n",
    "```\n",
    "# mapping.py\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# Load the column vector containing the dyssynchrony indices\n",
    "init_x = np.load(\"dyssync.npy\")\n",
    "\n",
    "# Multiply elementwise by 10, floor result, subtract 5\n",
    "x_scaled = np.multiply(init_x, 10)\n",
    "x_floor = np.floor(x_scaled)\n",
    "x = np.subtract(x_floor, 5)\n",
    "\n",
    "# Corner case: dyssynchrony index is between [0, 0.5)\n",
    "x[x < 0] = 0\n",
    "\n",
    "# Corner case: dyssynchrony index is 1.0\n",
    "x[x > 4] = 4\n",
    "\n",
    "# Convert each element to int \n",
    "x = x.astype(int)\n",
    "\n",
    "# Save to file \n",
    "np.save(\"target.npy\", x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Playing with the NumPy Dataset\n",
    "We will play around with the NumPy matrices that we have just created. The files of interest are as follows:\n",
    "* ```vcg.npy``` The VCG itself\n",
    "* ```vcg_length.npy``` The length of each VCG sequence\n",
    "* ```target.npy``` The class indices that the corresponding VCG lands in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCG Dimensions: (1210, 130, 3)\n",
      "VCG Sequence Length Dimensions: (1210,)\n",
      "VCG Sequence Class Indices: (1210,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import our length and vcg sequence and class index\n",
    "vcg = np.load(\"dataset/vcg.npy\")\n",
    "vcg_length = np.load(\"dataset/vcg_length.npy\")\n",
    "target = np.load(\"dataset/target.npy\")\n",
    "\n",
    "print \"VCG Dimensions: \" + str(vcg.shape)\n",
    "print \"VCG Sequence Length Dimensions: \" + str(vcg_length.shape)\n",
    "print \"VCG Sequence Class Indices: \" + str(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.17658654e-07,  -2.90673141e-06,   4.57174694e-06],\n",
       "       [  5.85916000e-03,   8.50800000e-04,  -6.00100000e-04],\n",
       "       [  1.88238800e-02,   2.74487000e-03,  -1.94500000e-03],\n",
       "       [  3.68574500e-02,   5.37931000e-03,  -3.82863000e-03],\n",
       "       [  5.84938100e-02,   8.55723000e-03,  -6.13386000e-03]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five timesteps of the 0th simulation\n",
    "vcg[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130, 130, 130, 130, 130])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five VCG sequence lengths\n",
    "vcg_length[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data type of each entry in the ```vcg.npy``` matrix is a 32 bit float whereas the data type of the ```vcg_length.npy``` matrix is a 32 bit int, to match the parameter requirements of ```sequence_length``` in ```tf.nn.dynamic_rnn```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All VCGs have 130 timesteps.\n"
     ]
    }
   ],
   "source": [
    "# Check that the length of each VCG is exactly 130 for Patient 6/7\n",
    "if vcg_length[vcg_length < 130]:\n",
    "    print \"Exists a VCG with a length not equal to 130 timesteps.\"\n",
    "else:\n",
    "    print \"All VCGs have 130 timesteps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all VCG's for Patient 6/7 have exactly 130 timesteps. It is possible that this feature does not exist in other patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCG Sequences #1-5 falls in classes: [4 2 2 2 3]\n",
      "VCG Sequence #187 falls in class: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the first five class indices\n",
    "print \"VCG Sequences #1-5 falls in classes: \" + str(target[:5])\n",
    "\n",
    "# VCG Sequence number 187 has a dyssynchrony index of 0.604\n",
    "# It should be mapped to class 1\n",
    "print \"VCG Sequence #187 falls in class: \" + str(target[186])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the necessary data in the correct format; we are now ready to create our wrapper class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Step 3: Create a Wrapper Class*\n",
    "Now that we've saved the dataset as NumPy files, we now create a Python class that can:\n",
    "* Provide the ```next_batch``` function.\n",
    "* Randomize the dataset, and store how we randomized it.\n",
    "* Store the sequence lengths of each VCG.\n",
    "\n",
    "This class will be called ```Simulations```. Within it, contains three members, ```train, validate,``` and ```test```, which correspond to the three subsets we will divide our dataset into. For clarification, the purpose of the three sets are as follows:\n",
    "* Training set: a set of examples used for learning the weights of the classifier.\n",
    "* Validation set: a set of examples used to tune the hyperparameters (architectures, not weights) of a classifier. We can use this to determine the optimum number of hidden units in a neural network.\n",
    "* Testing set: a set of examples used ONLY to access the performance of a fully specified classifier.\n",
    "\n",
    "For the purpose of simplifying implementation, we will pre-partition the training, validation, and testing sets, as well as fix the batch size to ```32``` examples. We will try to get the split as close to a ```60%, 20%, 20%``` split, but we will keep the set sizes divisble by ```32```. Thus, our set sizes will be as follows:\n",
    "* Training set: 416 examples, 13 batches (~68%)\n",
    "* Validation set: 96 examples, 3 batches (~16%)\n",
    "* Testing set: 96 examples, 3 batches (~16%)\n",
    "\n",
    "Which adds up to 608 examples and 19 batches.\n",
    "\n",
    "#### Playing Around with the Dataset Wrapper\n",
    "This is our final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 990\n",
      "Testing set size: 220\n"
     ]
    }
   ],
   "source": [
    "from dataset import Patient\n",
    "\n",
    "# Instantiate wrapper\n",
    "patient_dataset = Patient(\"dataset/vcg.npy\", \"dataset/vcg_length.npy\", \"dataset/target.npy\")\n",
    "\n",
    "# Sizes of sets\n",
    "print \"Training set size: \" + str(patient_dataset.train.randomize.max() + 1)\n",
    "print \"Testing set size: \" + str(patient_dataset.test.randomize.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of first example: 55\n",
      "Dimensions of VCG: (55, 130, 3)\n",
      "Dimensions of VCG lengths: (55,)\n",
      "Dimensions of targets: (55,)\n"
     ]
    }
   ],
   "source": [
    "# get the first batch\n",
    "batch_vcg, batch_vcg_length, batch_target = patient_dataset.train.next_batch()\n",
    "\n",
    "# Index of first example given in batch\n",
    "print \"Index of first example: \" + str(patient_dataset.train.index)\n",
    "\n",
    "# Shape of next batch\n",
    "print \"Dimensions of VCG: \" + str(batch_vcg.shape)\n",
    "print \"Dimensions of VCG lengths: \" + str(batch_vcg_length.shape)\n",
    "print \"Dimensions of targets: \" + str(batch_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[570 830  18 188  88 278 891 868  97 501 894 142 846 532 551 878 180 957\n",
      " 614  72 720 475 406 263 168 535 390  86 721 776 255 262 606 829 520 881\n",
      "  75 513 612 929 900 136 631 916 867 702 785 206 322 318 768 565  85 447\n",
      "  92 556 437 181 131 669 539 402 369 409 368 838  30 901 531 332 954 552\n",
      " 158 658  16 793  82 203 741  28 201 789 919 469 333 160 113  57 430  91\n",
      " 965 774 607 345 403 664 381  59 541 731 618  62 795 207 588 984 624 506\n",
      " 622 896 250 745 821 983 287 564 674 771  96 416 657 587 635 862 321 396\n",
      " 578 733 421 341 521  15 167 577 232 522 667 749 625 328 343 254  37 566\n",
      " 453 866 979 184 640 773 724 400 177  53 855 769 788 107  20 497 563 530\n",
      " 909 428 939 844 511 555 324 886 597 514 433 445 805 106 363 191 339 349\n",
      " 863 600 987 918 649 179 155  77  64 124 590 751 923  80 611 948  32 643\n",
      " 880 637 850 959 673 202 604 870 226 825 215 344 924 775 752 283 298  34\n",
      " 175 706 471 540 719 295 127 913 675 115 134 353 336 293 268 726 399   3\n",
      "  60 294 746 841  17 253 164 443  65 485  50 385 228 561  47 182 958 140\n",
      "  63 613 797 407 985  55 174 683 591 767 516 146 902 165 617 102 729 571\n",
      " 476  76 258 503 638 436 196 709 633 219 982 549 836 225 744 701 871 364\n",
      " 812 138 962 926 325 572 619 688 505 672 882 527 705 247 316 432 685 860\n",
      " 419 289 700 653 843  33 582 967 435 354 448 655 711 642 558 839 139 717\n",
      " 772 981 864 410 819 249 461 340 260 246   8 835 426 374 297 654 905   7\n",
      " 930 186 220 261 698 686  54  27  87 288 111 229 760 893 317 429 925 105\n",
      "  14 707 596 820 214 879  44 171 259 496 739 273 938 367 525 574 842 422\n",
      " 290 910 560 308 790 477  36  78 526 762 818 823 446 275  13 234 326 903\n",
      " 722 414 728 840 271 666  21 252 899 609 626 389 988 281  67 911 608 810\n",
      " 133 418 393 195 620 301 172 157  89 562 356 425 323 481 975 623 715 451\n",
      " 292  51  22 811 242  31 852 279 193 348 211 680 824 742 908 971 575 163\n",
      " 251 679 187 794 397 489 330 851  79 149 126 815 313 537 415 636 148 928\n",
      " 346 543 386   4 493  49 239 765 377 848 161  71 116 935 302 961 347 408\n",
      " 937 169 755  74 602 758 378 153 695  26 468 299 529 632 944 725 320 946\n",
      " 723 129 757 550 118 831 595 659 670 854 452 738 528 693 832 713 736 130\n",
      " 786 581 459 660 872 208 312   5 787 784 210  56 780 151 221 405 492 853\n",
      " 941 727 373 387 955 491 291 800 969 989 218 243 932 114 376 125 687 953\n",
      " 806 671 963 192 212  41 150 438 424 241 601 914 465 737 895 413 523 603\n",
      " 976 598 708 545 936  29  35 781 507 439 257  23 159 803 231 460  19 889\n",
      " 183 431 342 615 833 650 109 519 370 949 382 952 678 152 734 499 662 512\n",
      " 285 245 676 185 796 128 145 639 917 488 235 524 735 509 808 238 510 284\n",
      "  81 189 845 743 479 567 856 480 427  25 487 331 904 628 798 500 444   9\n",
      " 334   1 538 681 119 352 449 216 379 122 934 647 859 792 388 470 747 120\n",
      " 205 314 147 553  61 309 656   0 951 763 267 873 584 956 651 641 536 143\n",
      " 557 104 265 173 380 645 652 665 350  45  12 980 943  46 240 766 474 272\n",
      " 579 100  52 307 358 286 573 546 834 483 712  73 750 337 764 730  93 277\n",
      " 110 141 668  98 897 108 198 621 440 978 360 450  70 303 227 593 204 892\n",
      " 361 616 583 478 103 732 782 420 170 950 454 580 802 968 276 236 972 417\n",
      " 329 222 224 915 887 847 365 898  39 807 865 486 362 877 801 534 176 586\n",
      " 922 977 822 466 199 890 154 117 209 395 401 585 351 213 544 605 857  68\n",
      " 178 947 883 691 610  69 828 964 304 884 927 357 779 770 920 912 112 799\n",
      " 123 237  95  90 827  11 338 504 166 648 144 412 826  38 244 305 266 335\n",
      " 398 710 366  94 156 576 933 462 677 518 966   2 869 876 716 778 467  10\n",
      " 132 703 137 589 858 849 270 371 804 472 423 568 269 906 484 740 233 300\n",
      " 464 456 714 694 630 777 547 517 455 375 684 490 592 194 599 494  48 817\n",
      " 907 463 327 310 274 311  43 704 986 970  99 690 392 482 508 441 837 756\n",
      " 391 515 383 282 533 699 502 554 223 594  84 629 162 197 306 875 663 682\n",
      " 816 960 754 627 761 791 359  24 404  58 355 495 874 748 498 248 945 121\n",
      " 753  42 473 783 697 442 861 888 411 814 434 931 394  83 646 689 942 548\n",
      " 718 458 809 200 190 542 559 974 940 264  40 759 280 457 315 217 692   6\n",
      " 101 256 296 634 696 384 661 135 644 569 921 319 885 813  66 372 230 973]\n"
     ]
    }
   ],
   "source": [
    "# We can see the how the set was randomized by accessing the \"randomize\" member\n",
    "print patient_dataset.train.randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
