{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Wrapper\n",
    "I will be explaining the reasoning behind the implementation of the dataset wrapper for the vectorcardiograms and dyssynchrony indices.\n",
    "\n",
    "## Goal\n",
    "The goal is to be able to easily iterate through a given dataset when we are training a neural network. Ideally, we would want to be able to call ```next_batch``` and it would give us the next batch of a specified size within the dataset. \n",
    "\n",
    "## Next Batch\n",
    "We provide additional requirements of the ```next_batch``` function here. They are as follows:\n",
    "* Deliver a specified number of examples upon calling ```next_batch``` for the vectorcardiograms sequences, vectorcardiogram lengths, and the dyssynchrony indices.\n",
    "* The batches are delivered sequentially. For example, if we deliver the the first batch, it should contain example numbers 0 through 9. The second batch should deliver example numbers 10 through 20.\n",
    "* If we have iterated through the entire dataset, then start pulling batches from the beginning. This is reasonable because most often, neural networks are usually trained with more than one epoch (the network sees the entire dataset usually more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Steps\n",
    "### *Step 0: Setup*\n",
    "To download the dataset, please email Chris Villongco for the link to the Dropbox. Once you have access, download the folder ```BiV2``` that corresponds to Patient 2 (our choice of Patient 2 is arbitrary, and we can use any of the patients available). Within that folder, we find the following files and folders:\n",
    "* ```vcg_measured```* The actual (recorded) VCG (not simulated)\n",
    "* ```vcg_model/``` The VCG simulations\n",
    "* ```BiV2_LVdyssync_opt.txt```* The calculated dyssynchrony index (not from simulations)\n",
    "* ```BiV2_LVdyssync.txt``` The dyssynchrony indices resulting from the simulations\n",
    "* ```pts_to_eval.txt```* The parameters of the simulations\n",
    "\n",
    "\\* We are not interested in these files.\n",
    "\n",
    "Once you download and extract it (usually comes as a .zip file), run the following:\n",
    "```\n",
    ">>> cd BiV2/vcg_model\n",
    "```\n",
    "and we are ready to begin!\n",
    "\n",
    "### *Step 1: Rename Files*\n",
    "We wish to rename the files for three reasons:\n",
    "* Impose an ordering on the example numbers that is clearly visible in the file name\n",
    "* Make the filenames more readable\n",
    "* *Maintain* that the filenames are predictable and follow a well-defined format\n",
    "\n",
    "Thus, we will execute the following bash script to rename all the ```.txt``` files in the current directory into something more readable:\n",
    "```\n",
    "a=1\n",
    "for file in allParams-1_ECG_VCG_{1..608}_dump.txt; do \n",
    "    \n",
    "    # Require a 3 digit padding\n",
    "    new=$(printf \"version%03d.txt\" \"$a\")\n",
    "    \n",
    "    # Change the name\n",
    "    mv \"$file\" \"$new\"\n",
    "    let a=a+1\n",
    "done\n",
    "```\n",
    "The result will be 608 files that are renamed to ```version%%%.txt```, where the number is padded with three digits.\n",
    "\n",
    "\n",
    "Since the original filenames were not zero-padded, when we ```ls```, we would get ```allParams-1_ECG_VCG_109_dump.txt``` lexicographically before ```allParams-1_ECG_VCG_10_dump.txt```. Thus, instead of iterating through each ```file in ls *.txt```, we have to iterate through them using curly braces ```{1..608}``` to maintain that ```allParams-1_ECG_VCG_9_dump.txt``` corresponds to ```version009.txt``` and not ```allParams-1_ECG_VCG_109_dump.txt```\n",
    "\n",
    "To show that this has preserved the original ordering, look at the content of the file labelled ```1``` before and after the renaming.\n",
    "\n",
    "#### Before:\n",
    "```\n",
    ">>> head allParams-1_ECG_VCG_1_dump.txt\n",
    "1.14859698e-06\t-8.52689793e-07\t-1.62738886e-07\n",
    "6.27637865e-03\t8.56158099e-04\t-2.80092680e-05\n",
    "1.73977577e-02\t2.37706707e-03\t-8.70847085e-05\n",
    "0.03220872\t0.00439809\t-0.00017971\n",
    "0.04663505\t0.00636597\t-0.00028655\n",
    "0.05990819\t0.00821321\t-0.00043461\n",
    "0.07573148\t0.01035879\t-0.00061512\n",
    "0.09897242\t0.01347624\t-0.0008311\n",
    "0.11859204\t0.01606282\t-0.00100526\n",
    "0.13539736\t0.01838106\t-0.00139427\n",
    "```\n",
    "\n",
    "#### After:\n",
    "```\n",
    ">>> head version001.txt\n",
    "1.14859698e-06\t-8.52689793e-07\t-1.62738886e-07\n",
    "6.27637865e-03\t8.56158099e-04\t-2.80092680e-05\n",
    "1.73977577e-02\t2.37706707e-03\t-8.70847085e-05\n",
    "0.03220872\t0.00439809\t-0.00017971\n",
    "0.04663505\t0.00636597\t-0.00028655\n",
    "0.05990819\t0.00821321\t-0.00043461\n",
    "0.07573148\t0.01035879\t-0.00061512\n",
    "0.09897242\t0.01347624\t-0.0008311\n",
    "0.11859204\t0.01606282\t-0.00100526\n",
    "0.13539736\t0.01838106\t-0.00139427\n",
    "```\n",
    "The first ten lines appear to match. It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Step 2: Convert To NumPy Arrays*\n",
    "We wish to read in each VCG data as a NumPy 2D matrix and store them all in a list (creating a list of 2D matrices, thus becoming 3D). Similarly, we wish to read in each dyssynchrony index, a scalar value, and store them all as a column vector. We will read them in with simple python scripts, provided below (We provided the script as Markdown because it only needs to be executed once, and we have done it for you):\n",
    "\n",
    "#### Read in Vectorcardiogram Simulations with Python\n",
    "```\n",
    "# read_vcg.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize python list containing the vcg lengths and input \n",
    "vcg_length = []\n",
    "vcg = []\n",
    "\n",
    "for index in range(608):\n",
    "\n",
    "\t# Create filename with zero pad\n",
    "\tfilename = 'version{:03d}.txt'.format(index + 1)\n",
    "\n",
    "\t# Read in the text file as numpy matrix\n",
    "\tx = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "\tvcg.append(x)\n",
    "\n",
    "\t# Grab and store the vcg length\n",
    "\tvcg_length.append(x.shape[0])\n",
    "\n",
    "# Convert Python list to NumPy array and save\n",
    "np_vcg_length = np.asarray(vcg_length, dtype=np.int32)\n",
    "np.save(\"vcg_length.npy\", np_vcg_length)\n",
    "\n",
    "np_vcg = np.asarray(vcg, dtype=np.float32)\n",
    "np.save(\"vcg.npy\", np_vcg)\n",
    "\n",
    "```\n",
    "\n",
    "The result should be two files: ```vcg.npy``` and ```vcg_length.npy```, saved in our current directory. We save the length of each VCG simulation because the TensorFlow function ```tf.nn.dynamic_rnn``` accepts the optional parameter ```sequence_length```, an int32/int64 vector sized [batch_size] as a way of checking that the dimensions of our data reflect our design.\n",
    "\n",
    "#### Read in Dyssynchrony Indices With Python\n",
    "We do a similar thing with the corresponding dyssynchrony indices, but they are easier since they all lie in a single file. We run the following script (We provided the script as Markdown because it only needs to be executed once, and we have done it for you):\n",
    "```\n",
    "# read_dyssync.py\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "dyssync = np.loadtxt(\"dyssync.txt\")\n",
    "np.save(\"dyssync.npy\", dyssync)\n",
    "```\n",
    "\n",
    "#### Converting the Dyssynchrony Indices to Class Indices\n",
    "When we save the first file, ```dyssync.npy```, each entry is a real number value between ```0.5``` and ```1```. However, we need to map it to the set of class indices (what each VCG belongs to), namely, the integers between ```0``` and ```4```. The mapping is as follows:\n",
    "* Multiply by 10.\n",
    "* Floor the result.\n",
    "* Subtract 5.\n",
    "* Corner case: if the dyssynchrony index is less than 0.5 (0 is common), then we set those entries to ```0``` (instead of ```0*10 - 5 = -5```).\n",
    "* Corner case: if the dyssynchrony index is exactly 1, then we set those entries to ```4``` (instead of ```1*10 - 5 = 5```).\n",
    "* Convert to int datatype.\n",
    "\n",
    "We execute the following python script to implement the mapping and save it as a new ```.npy``` file:\n",
    "```\n",
    "# mapping.py\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# Load the column vector containing the dyssynchrony indices\n",
    "init_x = np.load(\"dyssync.npy\")\n",
    "\n",
    "# Multiply elementwise by 10, floor result, subtract 5\n",
    "x_scaled = np.multiply(init_x, 10)\n",
    "x_floor = np.floor(x_scaled)\n",
    "x = np.subtract(x_floor, 5)\n",
    "\n",
    "# Corner case: dyssynchrony index is between [0, 0.5)\n",
    "x[x < 0] = 0\n",
    "\n",
    "# Corner case: dyssynchrony index is 1.0\n",
    "x[x > 4] = 4\n",
    "\n",
    "# Convert each element to int \n",
    "x = x.astype(int)\n",
    "\n",
    "# Save to file \n",
    "np.save(\"target.npy\", x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Playing with the NumPy Dataset\n",
    "We will play around with the NumPy matrices that we have just created. The files of interest are as follows:\n",
    "* ```vcg.npy``` The VCG itself\n",
    "* ```vcg_length.npy``` The length of each VCG sequence\n",
    "* ```target.npy``` The class indices that the corresponding VCG lands in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCG Dimensions: (1817, 130, 3)\n",
      "VCG Sequence Length Dimensions: (1817,)\n",
      "VCG Sequence Class Indices: (1817,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import our length and vcg sequence and class index\n",
    "vcg = np.load(\"dataset/vcg.npy\")\n",
    "vcg_length = np.load(\"dataset/vcg_length.npy\")\n",
    "target = np.load(\"dataset/target.npy\")\n",
    "\n",
    "print \"VCG Dimensions: \" + str(vcg.shape)\n",
    "print \"VCG Sequence Length Dimensions: \" + str(vcg_length.shape)\n",
    "print \"VCG Sequence Class Indices: \" + str(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.17658654e-07,  -2.90673141e-06,   4.57174694e-06],\n",
       "       [  5.85916000e-03,   8.50800000e-04,  -6.00100000e-04],\n",
       "       [  1.88238800e-02,   2.74487000e-03,  -1.94500000e-03],\n",
       "       [  3.68574500e-02,   5.37931000e-03,  -3.82863000e-03],\n",
       "       [  5.84938100e-02,   8.55723000e-03,  -6.13386000e-03]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five timesteps of the 0th simulation\n",
    "vcg[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130, 130, 130, 130, 130])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five VCG sequence lengths\n",
    "vcg_length[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data type of each entry in the ```vcg.npy``` matrix is a 32 bit float whereas the data type of the ```vcg_length.npy``` matrix is a 32 bit int, to match the parameter requirements of ```sequence_length``` in ```tf.nn.dynamic_rnn```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All VCGs have 130 timesteps.\n"
     ]
    }
   ],
   "source": [
    "# Check that the length of each VCG is exactly 130 for Patient 6/7\n",
    "if vcg_length[vcg_length < 130]:\n",
    "    print \"Exists a VCG with a length not equal to 130 timesteps.\"\n",
    "else:\n",
    "    print \"All VCGs have 130 timesteps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all VCG's for Patient 6/7 have exactly 130 timesteps. It is possible that this feature does not exist in other patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCG Sequences #1-5 falls in classes: [4 2 2 2 3]\n",
      "VCG Sequence #187 falls in class: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the first five class indices\n",
    "print \"VCG Sequences #1-5 falls in classes: \" + str(target[:5])\n",
    "\n",
    "# VCG Sequence number 187 has a dyssynchrony index of 0.604\n",
    "# It should be mapped to class 1\n",
    "print \"VCG Sequence #187 falls in class: \" + str(target[186])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the necessary data in the correct format; we are now ready to create our wrapper class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Step 3: Create a Wrapper Class*\n",
    "Now that we've saved the dataset as NumPy files, we now create a Python class that can:\n",
    "* Provide the ```next_batch``` function.\n",
    "* Randomize the dataset, and store how we randomized it.\n",
    "* Store the sequence lengths of each VCG.\n",
    "\n",
    "This class will be called ```Simulations```. Within it, contains three members, ```train, validate,``` and ```test```, which correspond to the three subsets we will divide our dataset into. For clarification, the purpose of the three sets are as follows:\n",
    "* Training set: a set of examples used for learning the weights of the classifier.\n",
    "* Validation set: a set of examples used to tune the hyperparameters (architectures, not weights) of a classifier. We can use this to determine the optimum number of hidden units in a neural network.\n",
    "* Testing set: a set of examples used ONLY to access the performance of a fully specified classifier.\n",
    "\n",
    "For the purpose of simplifying implementation, we will pre-partition the training, validation, and testing sets, as well as fix the batch size to ```32``` examples. We will try to get the split as close to a ```60%, 20%, 20%``` split, but we will keep the set sizes divisble by ```32```. Thus, our set sizes will be as follows:\n",
    "* Training set: 416 examples, 13 batches (~68%)\n",
    "* Validation set: 96 examples, 3 batches (~16%)\n",
    "* Testing set: 96 examples, 3 batches (~16%)\n",
    "\n",
    "Which adds up to 608 examples and 19 batches.\n",
    "\n",
    "#### Playing Around with the Dataset Wrapper\n",
    "This is our final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1472\n",
      "Testing set size: 345\n"
     ]
    }
   ],
   "source": [
    "from dataset import Patient\n",
    "\n",
    "# Instantiate wrapper\n",
    "patient_dataset = Patient(\"dataset/vcg.npy\", \"dataset/vcg_length.npy\", \"dataset/target.npy\")\n",
    "\n",
    "# Sizes of sets\n",
    "print \"Training set size: \" + str(patient_dataset.train.randomize.max() + 1)\n",
    "print \"Testing set size: \" + str(patient_dataset.test.randomize.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of first example: 23\n",
      "Dimensions of VCG: (23, 130, 3)\n",
      "Dimensions of VCG lengths: (23,)\n",
      "Dimensions of targets: (23,)\n"
     ]
    }
   ],
   "source": [
    "# get the first batch\n",
    "batch_vcg, batch_vcg_length, batch_target = patient_dataset.train.next_batch()\n",
    "\n",
    "# Index of first example given in batch\n",
    "print \"Index of first example: \" + str(patient_dataset.train.index)\n",
    "\n",
    "# Shape of next batch\n",
    "print \"Dimensions of VCG: \" + str(batch_vcg.shape)\n",
    "print \"Dimensions of VCG lengths: \" + str(batch_vcg_length.shape)\n",
    "print \"Dimensions of targets: \" + str(batch_target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1375  885  524 ..., 1158  298 1191]\n"
     ]
    }
   ],
   "source": [
    "# We can see the how the set was randomized by accessing the \"randomize\" member\n",
    "print patient_dataset.train.randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
